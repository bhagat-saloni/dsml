{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Saloni_Fnu_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Fnu Saloni\n",
    "<br>\n",
    "Github Username: fnusaloni\n",
    "<br>\n",
    "USC ID: 3175644840"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activityName</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "      <td>dataset7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>bending1</td>\n",
       "      <td>dataset7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>42.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>16.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>bending1</td>\n",
       "      <td>dataset7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>42.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>bending1</td>\n",
       "      <td>dataset7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "      <td>dataset7.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42232</th>\n",
       "      <td>118500</td>\n",
       "      <td>40.25</td>\n",
       "      <td>1.30</td>\n",
       "      <td>12.67</td>\n",
       "      <td>1.70</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>cycling</td>\n",
       "      <td>dataset9.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42233</th>\n",
       "      <td>118750</td>\n",
       "      <td>41.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>2.49</td>\n",
       "      <td>cycling</td>\n",
       "      <td>dataset9.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42234</th>\n",
       "      <td>119000</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>16.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1.70</td>\n",
       "      <td>cycling</td>\n",
       "      <td>dataset9.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42235</th>\n",
       "      <td>119250</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.25</td>\n",
       "      <td>7.12</td>\n",
       "      <td>cycling</td>\n",
       "      <td>dataset9.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42236</th>\n",
       "      <td>119500</td>\n",
       "      <td>34.25</td>\n",
       "      <td>6.38</td>\n",
       "      <td>12.67</td>\n",
       "      <td>2.49</td>\n",
       "      <td>15.25</td>\n",
       "      <td>4.21</td>\n",
       "      <td>cycling</td>\n",
       "      <td>dataset9.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42237 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0           0      42.00       0.00      18.50       0.50      12.00   \n",
       "1         250      42.00       0.00      18.00       0.00      11.33   \n",
       "2         500      42.75       0.43      16.75       1.79      18.25   \n",
       "3         750      42.50       0.50      16.75       0.83      19.00   \n",
       "4        1000      43.00       0.82      16.25       0.83      18.00   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "42232  118500      40.25       1.30      12.67       1.70      20.50   \n",
       "42233  118750      41.75       1.79      11.00       6.00      16.67   \n",
       "42234  119000      36.33       0.47      16.00       3.16      20.33   \n",
       "42235  119250      31.50       1.50      21.00       0.00      12.25   \n",
       "42236  119500      34.25       6.38      12.67       2.49      15.25   \n",
       "\n",
       "       var_rss23 activityName       dataset  \n",
       "0           0.00     bending1  dataset7.csv  \n",
       "1           0.94     bending1  dataset7.csv  \n",
       "2           0.43     bending1  dataset7.csv  \n",
       "3           1.22     bending1  dataset7.csv  \n",
       "4           0.00     bending1  dataset7.csv  \n",
       "...          ...          ...           ...  \n",
       "42232       0.50      cycling  dataset9.csv  \n",
       "42233       2.49      cycling  dataset9.csv  \n",
       "42234       1.70      cycling  dataset9.csv  \n",
       "42235       7.12      cycling  dataset9.csv  \n",
       "42236       4.21      cycling  dataset9.csv  \n",
       "\n",
       "[42237 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = '../data/AReM'\n",
    "\n",
    "def getData(location):\n",
    "    # combining all the dataframes from different files into one\n",
    "    return pd.concat([\n",
    "        # opening and reading each file\n",
    "        pd.read_csv(os.path.join(location, activityName, file), \n",
    "                    # skiiping forst 5 rows as it doesnot contain any data and giving names to each column properly\n",
    "                    skiprows=5, header=None, \n",
    "                    names=['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23'], \n",
    "                    # since dataset4 of bending has the values in one colu only so using if for that else for rest dataset\n",
    "                    sep=r\"\\s+\" if (activityName == 'bending2' and file == 'dataset4.csv') else \",\",\n",
    "                    on_bad_lines='skip')\n",
    "        .assign(activityName=activityName, dataset=file)  # adding activity name and dataset name in the dataframe extra\n",
    "        # going through activity folders first\n",
    "        for activityName in os.listdir(location) if os.path.isdir(os.path.join(location, activityName))\n",
    "        # then going through csv files in each activity folder\n",
    "        for file in os.listdir(os.path.join(location, activityName)) if file.startswith('dataset') and file.endswith('.csv')\n",
    "    ], ignore_index=True)\n",
    "\n",
    "dataRead = getData(location)\n",
    "dataRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Dataset (Only bending2, dataset4.csv):\n",
      "         time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "11040       0      32.50       0.50       0.00       0.00      19.00   \n",
      "11041     250      32.50       0.50       0.00       0.00      18.50   \n",
      "11042     500      32.75       0.43       1.00       0.00      18.00   \n",
      "11043     750      32.50       0.50       0.00       0.00      17.50   \n",
      "11044    1000      32.50       0.50       7.50       0.50      17.50   \n",
      "...       ...        ...        ...        ...        ...        ...   \n",
      "11515  118750      28.67       0.47       4.67       1.25      17.33   \n",
      "11516  119000      27.50       0.50       5.50       2.50      17.25   \n",
      "11517  119250      28.00       0.00       6.67       0.94      17.00   \n",
      "11518  119500      28.00       0.00       5.00       0.82      17.00   \n",
      "11519  119750      28.00       0.00       0.00       0.00      17.00   \n",
      "\n",
      "       var_rss23 activityName       dataset  \n",
      "11040       1.00     bending2  dataset4.csv  \n",
      "11041       0.50     bending2  dataset4.csv  \n",
      "11042       0.00     bending2  dataset4.csv  \n",
      "11043       0.50     bending2  dataset4.csv  \n",
      "11044       0.87     bending2  dataset4.csv  \n",
      "...          ...          ...           ...  \n",
      "11515       0.47     bending2  dataset4.csv  \n",
      "11516       1.30     bending2  dataset4.csv  \n",
      "11517       1.00     bending2  dataset4.csv  \n",
      "11518       0.71     bending2  dataset4.csv  \n",
      "11519       1.00     bending2  dataset4.csv  \n",
      "\n",
      "[480 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# seeing the data for bending 2's dataset 4 that is it proper or not\n",
    "bending2Ds4 = dataRead[(dataRead['activityName'] == 'bending2') & (dataRead['dataset'] == 'dataset4.csv')]\n",
    "\n",
    "print(\"\\nFiltered Dataset (Only bending2, dataset4.csv):\")\n",
    "print(bending2Ds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 69 \n",
      "Test instances: 19\n",
      "\n",
      "Total instances: 88\n",
      "\n",
      "Training files: ['../data/AReM/bending1/dataset3.csv', '../data/AReM/bending1/dataset4.csv', '../data/AReM/bending1/dataset5.csv', '../data/AReM/bending1/dataset6.csv', '../data/AReM/bending1/dataset7.csv', '../data/AReM/bending2/dataset3.csv', '../data/AReM/bending2/dataset4.csv', '../data/AReM/bending2/dataset5.csv', '../data/AReM/bending2/dataset6.csv', '../data/AReM/cycling/dataset4.csv', '../data/AReM/cycling/dataset5.csv', '../data/AReM/cycling/dataset6.csv', '../data/AReM/cycling/dataset7.csv', '../data/AReM/cycling/dataset8.csv', '../data/AReM/cycling/dataset9.csv', '../data/AReM/cycling/dataset10.csv', '../data/AReM/cycling/dataset11.csv', '../data/AReM/cycling/dataset12.csv', '../data/AReM/cycling/dataset13.csv', '../data/AReM/cycling/dataset14.csv', '../data/AReM/cycling/dataset15.csv', '../data/AReM/lying/dataset4.csv', '../data/AReM/lying/dataset5.csv', '../data/AReM/lying/dataset6.csv', '../data/AReM/lying/dataset7.csv', '../data/AReM/lying/dataset8.csv', '../data/AReM/lying/dataset9.csv', '../data/AReM/lying/dataset10.csv', '../data/AReM/lying/dataset11.csv', '../data/AReM/lying/dataset12.csv', '../data/AReM/lying/dataset13.csv', '../data/AReM/lying/dataset14.csv', '../data/AReM/lying/dataset15.csv', '../data/AReM/sitting/dataset4.csv', '../data/AReM/sitting/dataset5.csv', '../data/AReM/sitting/dataset6.csv', '../data/AReM/sitting/dataset7.csv', '../data/AReM/sitting/dataset8.csv', '../data/AReM/sitting/dataset9.csv', '../data/AReM/sitting/dataset10.csv', '../data/AReM/sitting/dataset11.csv', '../data/AReM/sitting/dataset12.csv', '../data/AReM/sitting/dataset13.csv', '../data/AReM/sitting/dataset14.csv', '../data/AReM/sitting/dataset15.csv', '../data/AReM/standing/dataset4.csv', '../data/AReM/standing/dataset5.csv', '../data/AReM/standing/dataset6.csv', '../data/AReM/standing/dataset7.csv', '../data/AReM/standing/dataset8.csv', '../data/AReM/standing/dataset9.csv', '../data/AReM/standing/dataset10.csv', '../data/AReM/standing/dataset11.csv', '../data/AReM/standing/dataset12.csv', '../data/AReM/standing/dataset13.csv', '../data/AReM/standing/dataset14.csv', '../data/AReM/standing/dataset15.csv', '../data/AReM/walking/dataset4.csv', '../data/AReM/walking/dataset5.csv', '../data/AReM/walking/dataset6.csv', '../data/AReM/walking/dataset7.csv', '../data/AReM/walking/dataset8.csv', '../data/AReM/walking/dataset9.csv', '../data/AReM/walking/dataset10.csv', '../data/AReM/walking/dataset11.csv', '../data/AReM/walking/dataset12.csv', '../data/AReM/walking/dataset13.csv', '../data/AReM/walking/dataset14.csv', '../data/AReM/walking/dataset15.csv']\n",
      "\n",
      "Testing files: ['../data/AReM/bending1/dataset1.csv', '../data/AReM/bending1/dataset2.csv', '../data/AReM/bending2/dataset1.csv', '../data/AReM/bending2/dataset2.csv', '../data/AReM/cycling/dataset1.csv', '../data/AReM/cycling/dataset2.csv', '../data/AReM/cycling/dataset3.csv', '../data/AReM/lying/dataset1.csv', '../data/AReM/lying/dataset2.csv', '../data/AReM/lying/dataset3.csv', '../data/AReM/sitting/dataset1.csv', '../data/AReM/sitting/dataset2.csv', '../data/AReM/sitting/dataset3.csv', '../data/AReM/standing/dataset1.csv', '../data/AReM/standing/dataset2.csv', '../data/AReM/standing/dataset3.csv', '../data/AReM/walking/dataset1.csv', '../data/AReM/walking/dataset2.csv', '../data/AReM/walking/dataset3.csv']\n",
      "\n",
      "Testing Data:\n",
      "        time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "0          0      39.25       0.43      22.75       0.43      33.75   \n",
      "1        250      39.25       0.43      23.00       0.00      33.00   \n",
      "2        500      39.25       0.43      23.25       0.43      33.00   \n",
      "3        750      39.50       0.50      23.00       0.71      33.00   \n",
      "4       1000      39.50       0.50      24.00       0.00      33.00   \n",
      "...      ...        ...        ...        ...        ...        ...   \n",
      "9115  118750      36.00       2.45      17.00       5.10      20.50   \n",
      "9116  119000      34.33       1.89      15.00       2.45      17.00   \n",
      "9117  119250      33.00       7.35      14.60       3.14      13.00   \n",
      "9118  119500      31.67       1.25      11.00       6.16      19.25   \n",
      "9119  119750      30.75      10.21      11.75       1.09      18.50   \n",
      "\n",
      "      var_rss23 activityName  \n",
      "0          1.30     bending1  \n",
      "1          0.00     bending1  \n",
      "2          0.00     bending1  \n",
      "3          0.00     bending1  \n",
      "4          0.00     bending1  \n",
      "...         ...          ...  \n",
      "9115       0.87      walking  \n",
      "9116       2.12      walking  \n",
      "9117       5.70      walking  \n",
      "9118       2.17      walking  \n",
      "9119       3.20      walking  \n",
      "\n",
      "[9120 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "location = '../data/AReM'\n",
    "\n",
    "# making the activity list\n",
    "activitiesGiven = ['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']\n",
    "\n",
    "# keeping datasets 1 and 2 in folders bending1 and bending2, as well as datasets 1, 2, and 3 in other folders as test data\n",
    "testData = {}\n",
    "for activity in activitiesGiven:\n",
    "    if activity in ['bending1', 'bending2']:\n",
    "        testData[activity] = [1, 2]  \n",
    "    else:\n",
    "        testData[activity] = [1, 2, 3]\n",
    "\n",
    "# considering other datasets as train data\n",
    "trainData = {\n",
    "    'bending1': list(range(3, 8)),\n",
    "    'bending2': list(range(3, 7)),\n",
    "}\n",
    "for activity in activitiesGiven:\n",
    "    if activity not in trainData:\n",
    "        trainData[activity] = list(range(4, 16))  \n",
    "\n",
    "# using this function to gather training or testing data in one place\n",
    "def gatherDataset(dataType, isTrainData=False):\n",
    "    dataframes = []\n",
    "    fileNames = []\n",
    "    \n",
    "    # counting the number of dataset files for training or testing data\n",
    "    datasetTotalCount = sum(len(datasetIds) for datasetIds in dataType.values())\n",
    "\n",
    "    for activityName, datasetIds in dataType.items():\n",
    "        for datasetId in datasetIds:\n",
    "            # getting the path to each file\n",
    "            fileLoc = os.path.join(location, activityName, f'dataset{datasetId}.csv')\n",
    "            \n",
    "            # since dataset4 of bending2 has values in one column only, handling it separately\n",
    "            if isTrainData and activityName == 'bending2' and datasetId == 4:\n",
    "                df = pd.read_csv(fileLoc, skiprows=5, header=None, \n",
    "                                 names=['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23'], \n",
    "                                 sep=r\"\\s+\", engine='python', on_bad_lines='skip')\n",
    "            else:\n",
    "                df = pd.read_csv(fileLoc, skiprows=5, header=None, \n",
    "                                 names=['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23'], \n",
    "                                 sep=\",\", on_bad_lines='skip')\n",
    "\n",
    "            # adding activity name as an extra column\n",
    "            df['activityName'] = activityName  \n",
    "            dataframes.append(df)\n",
    "            fileNames.append(fileLoc)\n",
    "\n",
    "    # merging all datasets into one\n",
    "    return pd.concat(dataframes, ignore_index=True), fileNames, datasetTotalCount\n",
    "\n",
    "# calling the function twice to load training and testing data\n",
    "trainDataframe, trainFileName, trainIns = gatherDataset(trainData, isTrainData=True)\n",
    "testDataframe, testFileName, testIns = gatherDataset(testData, isTrainData=False)\n",
    "\n",
    "# showing the result\n",
    "print(f\"Training instances: {trainIns} \\nTest instances: {testIns}\")\n",
    "print(f\"\\nTotal instances: {trainIns + testIns}\")\n",
    "print(f\"\\nTraining files: {trainFileName}\")\n",
    "print(f\"\\nTesting files: {testFileName}\")\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "print(testDataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20.25</td>\n",
       "      <td>1.48</td>\n",
       "      <td>31.25</td>\n",
       "      <td>1.09</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>40.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33112</th>\n",
       "      <td>118750</td>\n",
       "      <td>34.50</td>\n",
       "      <td>6.18</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>12.67</td>\n",
       "      <td>4.19</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33113</th>\n",
       "      <td>119000</td>\n",
       "      <td>25.75</td>\n",
       "      <td>6.02</td>\n",
       "      <td>13.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>16.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33114</th>\n",
       "      <td>119250</td>\n",
       "      <td>31.50</td>\n",
       "      <td>3.35</td>\n",
       "      <td>10.25</td>\n",
       "      <td>5.12</td>\n",
       "      <td>16.25</td>\n",
       "      <td>2.95</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33115</th>\n",
       "      <td>119500</td>\n",
       "      <td>33.75</td>\n",
       "      <td>2.77</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.24</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33116</th>\n",
       "      <td>119750</td>\n",
       "      <td>37.00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>18.25</td>\n",
       "      <td>3.70</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33117 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0           0      42.00       0.71      21.25       0.43      30.00   \n",
       "1         250      41.50       0.50      20.25       1.48      31.25   \n",
       "2         500      41.50       0.50      14.25       1.92      33.00   \n",
       "3         750      40.75       0.83      15.75       0.43      33.00   \n",
       "4        1000      40.00       0.71      20.00       2.74      32.75   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "33112  118750      34.50       6.18       9.00       3.56      12.67   \n",
       "33113  119000      25.75       6.02      13.75       2.05      16.00   \n",
       "33114  119250      31.50       3.35      10.25       5.12      16.25   \n",
       "33115  119500      33.75       2.77      14.00       3.24      13.75   \n",
       "33116  119750      37.00       1.41      18.25       3.70      11.00   \n",
       "\n",
       "       var_rss23 activityName  \n",
       "0           0.00     bending1  \n",
       "1           1.09     bending1  \n",
       "2           0.00     bending1  \n",
       "3           0.00     bending1  \n",
       "4           0.43     bending1  \n",
       "...          ...          ...  \n",
       "33112       4.19      walking  \n",
       "33113       1.58      walking  \n",
       "33114       2.95      walking  \n",
       "33115       0.43      walking  \n",
       "33116       4.32      walking  \n",
       "\n",
       "[33117 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing train data\n",
    "print(\"Train Data:\")\n",
    "trainDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types of time-domain features are usually used in time series classification are:\n",
    "a) Mean: It is the average value of the dataset.                                         \n",
    "b) Median: It is the middle value when the data is arranged in order.                    \n",
    "c) Mode: It is the most frequently occurring value in the dataset.                       \n",
    "d) Maximum and Minimum: It is the highest and lowest values in the dataset helping to identify extremes.                                                                      \n",
    "e) Interquartile Range (IQR): It focuses on the middle 50% of the data ignoring extreme values that might distort the analysis.                                                \n",
    "f) Range: It is the difference between the max and min values showing how wide the spread is.                                                                           \n",
    "g) Variance: It measures how spread out the data is from the mean. High variance means values fluctuate a lot, while low variance means they stay close to the mean.         \n",
    "h) Standard Deviation: It is an another way to measure spread and is just the square root of variance.                                                                     \n",
    "i) Percentiles: It splits the data into sections just like the median in order to understand how values are distributed.                                              \n",
    "j) Autocorrelation: It checks how similar the data is to its past values and is great for finding repeating patterns, like daily or seasonal trends.                       \n",
    "k) Zero-Crossing Rate: It counts how often the signal changes from positive to negative or vice versa.                                                                     \n",
    "l) Root Mean Square (RMS): It measures the overall energy or intensity of the data.      \n",
    "m) Kurtosis: It helps us understand if the data has a sharp peak ie many values near the center or if it’s more spread out.                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>activityName</th>\n",
       "      <th>min_1</th>\n",
       "      <th>max_1</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>median_1</th>\n",
       "      <th>std_1</th>\n",
       "      <th>1st_quart_1</th>\n",
       "      <th>3rd_quart_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_5</th>\n",
       "      <th>1st_quart_5</th>\n",
       "      <th>3rd_quart_5</th>\n",
       "      <th>min_6</th>\n",
       "      <th>max_6</th>\n",
       "      <th>mean_6</th>\n",
       "      <th>median_6</th>\n",
       "      <th>std_6</th>\n",
       "      <th>1st_quart_6</th>\n",
       "      <th>3rd_quart_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset1.csv</td>\n",
       "      <td>bending1</td>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.2500</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset1.csv</td>\n",
       "      <td>bending2</td>\n",
       "      <td>12.75</td>\n",
       "      <td>51.00</td>\n",
       "      <td>24.562958</td>\n",
       "      <td>24.25</td>\n",
       "      <td>3.737514</td>\n",
       "      <td>23.1875</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.693786</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.700187</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.693720</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset1.csv</td>\n",
       "      <td>cycling</td>\n",
       "      <td>24.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>37.177042</td>\n",
       "      <td>36.25</td>\n",
       "      <td>3.581301</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>40.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.890347</td>\n",
       "      <td>17.9500</td>\n",
       "      <td>21.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>2.921729</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.852600</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset1.csv</td>\n",
       "      <td>lying</td>\n",
       "      <td>23.50</td>\n",
       "      <td>30.00</td>\n",
       "      <td>27.716375</td>\n",
       "      <td>27.50</td>\n",
       "      <td>1.442253</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.074511</td>\n",
       "      <td>5.5000</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.613688</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset1.csv</td>\n",
       "      <td>sitting</td>\n",
       "      <td>33.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>42.363562</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2.068247</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>43.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.956821</td>\n",
       "      <td>10.1875</td>\n",
       "      <td>17.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.034021</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.985627</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>dataset9.csv</td>\n",
       "      <td>cycling</td>\n",
       "      <td>27.75</td>\n",
       "      <td>44.67</td>\n",
       "      <td>37.142359</td>\n",
       "      <td>36.33</td>\n",
       "      <td>3.762442</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>40.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.687173</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>18.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2.825720</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.637312</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>dataset9.csv</td>\n",
       "      <td>lying</td>\n",
       "      <td>39.00</td>\n",
       "      <td>56.25</td>\n",
       "      <td>47.325125</td>\n",
       "      <td>42.67</td>\n",
       "      <td>5.961280</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.142132</td>\n",
       "      <td>11.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.766167</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.723953</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>dataset9.csv</td>\n",
       "      <td>sitting</td>\n",
       "      <td>41.75</td>\n",
       "      <td>46.50</td>\n",
       "      <td>43.190854</td>\n",
       "      <td>42.50</td>\n",
       "      <td>1.230345</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>44.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.027169</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.806229</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.645476</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dataset9.csv</td>\n",
       "      <td>standing</td>\n",
       "      <td>36.33</td>\n",
       "      <td>47.67</td>\n",
       "      <td>45.399625</td>\n",
       "      <td>45.50</td>\n",
       "      <td>1.328121</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>46.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.374095</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.795104</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.503007</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>dataset9.csv</td>\n",
       "      <td>walking</td>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.75</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.2500</td>\n",
       "      <td>37.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992920</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset activityName  min_1  max_1     mean_1  median_1     std_1  \\\n",
       "0   dataset1.csv     bending1  37.25  45.00  40.624792     40.50  1.476967   \n",
       "1   dataset1.csv     bending2  12.75  51.00  24.562958     24.25  3.737514   \n",
       "2   dataset1.csv      cycling  24.25  45.00  37.177042     36.25  3.581301   \n",
       "3   dataset1.csv        lying  23.50  30.00  27.716375     27.50  1.442253   \n",
       "4   dataset1.csv      sitting  33.25  48.00  42.363562     43.00  2.068247   \n",
       "..           ...          ...    ...    ...        ...       ...       ...   \n",
       "83  dataset9.csv      cycling  27.75  44.67  37.142359     36.33  3.762442   \n",
       "84  dataset9.csv        lying  39.00  56.25  47.325125     42.67  5.961280   \n",
       "85  dataset9.csv      sitting  41.75  46.50  43.190854     42.50  1.230345   \n",
       "86  dataset9.csv     standing  36.33  47.67  45.399625     45.50  1.328121   \n",
       "87  dataset9.csv      walking  15.50  43.67  34.225875     34.75  4.441798   \n",
       "\n",
       "    1st_quart_1  3rd_quart_1  min_2  ...     std_5  1st_quart_5  3rd_quart_5  \\\n",
       "0       39.2500        42.00    0.0  ...  2.188449      33.0000        36.00   \n",
       "1       23.1875        26.50    0.0  ...  3.693786      20.5000        27.00   \n",
       "2       34.5000        40.25    0.0  ...  2.890347      17.9500        21.75   \n",
       "3       27.0000        29.00    0.0  ...  4.074511       5.5000        10.75   \n",
       "4       42.0000        43.50    0.0  ...  4.956821      10.1875        17.69   \n",
       "..          ...          ...    ...  ...       ...          ...          ...   \n",
       "83      34.0000        40.50    0.0  ...  2.687173      15.0000        18.75   \n",
       "84      42.0000        54.00    0.0  ...  4.142132      11.7500        18.00   \n",
       "85      42.0000        44.50    0.0  ...  3.027169      14.0000        18.33   \n",
       "86      45.0000        46.33    0.0  ...  3.374095      11.2500        14.50   \n",
       "87      31.2500        37.25    0.0  ...  2.992920      14.3300        18.25   \n",
       "\n",
       "    min_6  max_6    mean_6  median_6     std_6  1st_quart_6  3rd_quart_6  \n",
       "0     0.0   1.92  0.570583      0.43  0.582915         0.00       1.3000  \n",
       "1     0.0   4.97  0.700187      0.50  0.693720         0.43       0.8700  \n",
       "2     0.0   9.34  2.921729      2.50  1.852600         1.50       3.9000  \n",
       "3     0.0   4.50  0.734271      0.71  0.613688         0.43       1.0000  \n",
       "4     0.0   6.02  1.034021      0.83  0.985627         0.47       1.2500  \n",
       "..    ...    ...       ...       ...       ...          ...          ...  \n",
       "83    0.0   8.75  2.825720      2.59  1.637312         1.59       3.7400  \n",
       "84    0.0   5.72  0.766167      0.50  0.723953         0.43       1.0000  \n",
       "85    0.0   5.45  0.806229      0.82  0.645476         0.43       1.0900  \n",
       "86    0.0   4.50  0.795104      0.82  0.503007         0.47       1.0000  \n",
       "87    0.0   9.42  3.479542      3.27  1.761146         2.24       4.5375  \n",
       "\n",
       "[88 rows x 44 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of column names\n",
    "columnName = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "# calculating statistical features for the dataset\n",
    "def calculation(dataRead):\n",
    "    # grouping the data by dataset and activityName\n",
    "    grpData = dataRead.groupby(['dataset', 'activityName'])[columnName]\n",
    "\n",
    "    # calculating statistical features for each group\n",
    "    newDataset = grpData.agg([\n",
    "        ('min', 'min'),\n",
    "        ('max', 'max'),\n",
    "        ('mean', 'mean'),\n",
    "        ('median', 'median'),\n",
    "        ('std', 'std'),\n",
    "        ('1st_quart', lambda x: x.quantile(0.25)),\n",
    "        ('3rd_quart', lambda x: x.quantile(0.75))\n",
    "    ]).reset_index()\n",
    "\n",
    "    # formatting column names\n",
    "    newDataset.columns = ['_'.join(col).strip('_') for col in newDataset.columns]\n",
    "\n",
    "    # renaming columns for proper presentation\n",
    "    renameCol = {}\n",
    "    for x, colName in enumerate(columnName):\n",
    "        for stat in ['min', 'max', 'mean', 'median', 'std', '1st_quart', '3rd_quart']:\n",
    "            renameCol[f\"{colName}_{stat}\"] = f\"{stat}_{x+1}\"\n",
    "\n",
    "    # renaming dataset\n",
    "    newDataset.rename(columns=renameCol, inplace=True)\n",
    "\n",
    "    return newDataset\n",
    "\n",
    "# using the calculation function for dataRead\n",
    "calculatedDataset = calculation(dataRead)\n",
    "calculatedDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Standard Deviations:\n",
      "min_1          9.569975\n",
      "max_1          4.394362\n",
      "mean_1         5.335700\n",
      "median_1       5.440054\n",
      "std_1          1.772185\n",
      "1st_quart_1    6.153874\n",
      "3rd_quart_1    5.138925\n",
      "min_2          0.000000\n",
      "max_2          5.062729\n",
      "mean_2         1.574198\n",
      "median_2       1.412293\n",
      "std_2          0.884137\n",
      "1st_quart_2    0.946386\n",
      "3rd_quart_2    2.125399\n",
      "min_3          2.956462\n",
      "max_3          4.875137\n",
      "mean_3         4.008228\n",
      "median_3       4.036396\n",
      "std_3          0.946670\n",
      "1st_quart_3    4.220658\n",
      "3rd_quart_3    4.171628\n",
      "min_4          0.000000\n",
      "max_4          2.183625\n",
      "mean_4         1.166178\n",
      "median_4       1.145985\n",
      "std_4          0.458283\n",
      "1st_quart_4    0.843405\n",
      "3rd_quart_4    1.552504\n",
      "min_5          6.124001\n",
      "max_5          5.741238\n",
      "mean_5         5.675543\n",
      "median_5       5.813782\n",
      "std_5          1.024918\n",
      "1st_quart_5    6.096465\n",
      "3rd_quart_5    5.531720\n",
      "min_6          0.045838\n",
      "max_6          2.518921\n",
      "mean_6         1.154889\n",
      "median_6       1.086474\n",
      "std_6          0.517651\n",
      "1st_quart_6    0.758687\n",
      "3rd_quart_6    1.523739\n",
      "dtype: float64\n",
      "\n",
      "Bootstrap 90% Confidence Intervals for Standard Deviations:\n",
      "             Lower CI   Upper CI\n",
      "min_1        8.190039  10.750919\n",
      "max_1        3.329536   5.206520\n",
      "mean_1       4.673331   5.834515\n",
      "median_1     4.747001   5.999267\n",
      "std_1        1.552910   1.939561\n",
      "1st_quart_1  5.572502   6.563460\n",
      "3rd_quart_1  4.275972   5.820735\n",
      "min_2        0.000000   0.000000\n",
      "max_2        4.607637   5.369827\n",
      "mean_2       1.397628   1.696595\n",
      "median_2     1.226715   1.528603\n",
      "std_2        0.795277   0.935959\n",
      "1st_quart_2  0.826380   1.029858\n",
      "3rd_quart_2  1.869445   2.300275\n",
      "min_3        2.738632   3.092634\n",
      "max_3        4.143472   5.384886\n",
      "mean_3       3.422683   4.501606\n",
      "median_3     3.372537   4.498345\n",
      "std_3        0.765206   1.102945\n",
      "1st_quart_3  3.618411   4.695018\n",
      "3rd_quart_3  3.543235   4.650519\n",
      "min_4        0.000000   0.000000\n",
      "max_4        1.953773   2.341975\n",
      "mean_4       1.067818   1.211788\n",
      "median_4     1.047356   1.198805\n",
      "std_4        0.418125   0.483600\n",
      "1st_quart_4  0.767399   0.886121\n",
      "3rd_quart_4  1.430474   1.617830\n",
      "min_5        4.437991   7.518136\n",
      "max_5        4.775718   6.542164\n",
      "mean_5       4.382061   6.681946\n",
      "median_5     4.441010   6.950871\n",
      "std_5        0.803196   1.212676\n",
      "1st_quart_5  4.868761   7.164411\n",
      "3rd_quart_5  4.374486   6.612336\n",
      "min_6        0.000000   0.078029\n",
      "max_6        2.253556   2.725684\n",
      "mean_6       1.052809   1.210042\n",
      "median_6     0.983844   1.139723\n",
      "std_6        0.478991   0.543884\n",
      "1st_quart_6  0.686010   0.806372\n",
      "3rd_quart_6  1.400217   1.591634\n"
     ]
    }
   ],
   "source": [
    "# selecting only the numeric columns\n",
    "numFeature = calculatedDataset.select_dtypes(include=[np.number])\n",
    "\n",
    "# # calculating standard deviation for each feature\n",
    "# def calStd(dataRead):\n",
    "#     return dataRead.std()\n",
    "\n",
    "# calculating bootstrap CI\n",
    "def calBootCI(dataRead, numBootstrap=1000, confidenceLevel=0.90):\n",
    "    bootStds = np.zeros(numBootstrap)  \n",
    "\n",
    "    # randomly selecting data points from dataRead with replacement to create a new sample and calculating standard deviation for that\n",
    "    for x in range(numBootstrap):\n",
    "        select = np.random.choice(dataRead, size=len(dataRead), replace=True)  \n",
    "        bootStds[x] = np.std(select)  \n",
    "\n",
    "    # calculating CI\n",
    "    lowerCi = np.percentile(bootStds, 5)  # 5th percentile\n",
    "    upperCi = np.percentile(bootStds, 95)  # 95th percentile\n",
    "\n",
    "    return lowerCi, upperCi\n",
    "\n",
    "# calculating standard deviation for each feature\n",
    "origStds = numFeature.std()\n",
    "\n",
    "# calculating bootstrap CI for each feature\n",
    "CI = np.array([calBootCI(numFeature[col]) for col in numFeature.columns])\n",
    "\n",
    "# converting CI into a dataframe\n",
    "CIDataframe = pd.DataFrame(CI, index=numFeature.columns, columns=[\"Lower CI\", \"Upper CI\"])\n",
    "\n",
    "\n",
    "print(\"\\nOriginal Standard Deviations:\")\n",
    "print(origStds)\n",
    "\n",
    "print(\"\\nBootstrap 90% Confidence Intervals for Standard Deviations:\")\n",
    "print(CIDataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Statistics - Mean, Std, Range per Activity :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_1_mean</th>\n",
       "      <th>min_1_std</th>\n",
       "      <th>min_1_&lt;lambda_0&gt;</th>\n",
       "      <th>max_1_mean</th>\n",
       "      <th>max_1_std</th>\n",
       "      <th>max_1_&lt;lambda_0&gt;</th>\n",
       "      <th>mean_1_mean</th>\n",
       "      <th>mean_1_std</th>\n",
       "      <th>mean_1_&lt;lambda_0&gt;</th>\n",
       "      <th>median_1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>median_6_&lt;lambda_0&gt;</th>\n",
       "      <th>std_6_mean</th>\n",
       "      <th>std_6_std</th>\n",
       "      <th>std_6_&lt;lambda_0&gt;</th>\n",
       "      <th>1st_quart_6_mean</th>\n",
       "      <th>1st_quart_6_std</th>\n",
       "      <th>1st_quart_6_&lt;lambda_0&gt;</th>\n",
       "      <th>3rd_quart_6_mean</th>\n",
       "      <th>3rd_quart_6_std</th>\n",
       "      <th>3rd_quart_6_&lt;lambda_0&gt;</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activityName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bending1</th>\n",
       "      <td>35.642857</td>\n",
       "      <td>2.030277</td>\n",
       "      <td>5.00</td>\n",
       "      <td>46.795714</td>\n",
       "      <td>1.275524</td>\n",
       "      <td>3.00</td>\n",
       "      <td>42.667723</td>\n",
       "      <td>1.250419</td>\n",
       "      <td>3.344333</td>\n",
       "      <td>42.904286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.531610</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.233369</td>\n",
       "      <td>0.061429</td>\n",
       "      <td>0.162525</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.279804</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bending2</th>\n",
       "      <td>17.541667</td>\n",
       "      <td>9.995520</td>\n",
       "      <td>27.50</td>\n",
       "      <td>44.958333</td>\n",
       "      <td>6.581065</td>\n",
       "      <td>18.00</td>\n",
       "      <td>29.415344</td>\n",
       "      <td>2.920310</td>\n",
       "      <td>8.023250</td>\n",
       "      <td>28.993333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.905411</td>\n",
       "      <td>0.301775</td>\n",
       "      <td>0.851877</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.168333</td>\n",
       "      <td>0.205175</td>\n",
       "      <td>0.4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycling</th>\n",
       "      <td>24.377333</td>\n",
       "      <td>3.358966</td>\n",
       "      <td>10.25</td>\n",
       "      <td>44.483333</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>1.50</td>\n",
       "      <td>36.747290</td>\n",
       "      <td>0.520192</td>\n",
       "      <td>1.808833</td>\n",
       "      <td>36.221667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>1.749547</td>\n",
       "      <td>0.111433</td>\n",
       "      <td>0.395348</td>\n",
       "      <td>1.721167</td>\n",
       "      <td>0.230244</td>\n",
       "      <td>0.760</td>\n",
       "      <td>4.038333</td>\n",
       "      <td>0.281337</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lying</th>\n",
       "      <td>33.216667</td>\n",
       "      <td>12.334934</td>\n",
       "      <td>48.00</td>\n",
       "      <td>42.733333</td>\n",
       "      <td>8.639697</td>\n",
       "      <td>26.25</td>\n",
       "      <td>39.850217</td>\n",
       "      <td>7.142058</td>\n",
       "      <td>20.287792</td>\n",
       "      <td>39.278000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.560337</td>\n",
       "      <td>0.119245</td>\n",
       "      <td>0.335581</td>\n",
       "      <td>0.340833</td>\n",
       "      <td>0.179044</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.080858</td>\n",
       "      <td>0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sitting</th>\n",
       "      <td>35.544667</td>\n",
       "      <td>6.528011</td>\n",
       "      <td>19.00</td>\n",
       "      <td>46.356000</td>\n",
       "      <td>2.908998</td>\n",
       "      <td>12.08</td>\n",
       "      <td>41.748634</td>\n",
       "      <td>3.424276</td>\n",
       "      <td>13.011688</td>\n",
       "      <td>41.359000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.821134</td>\n",
       "      <td>0.150418</td>\n",
       "      <td>0.542337</td>\n",
       "      <td>0.445333</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>0.194008</td>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standing</th>\n",
       "      <td>34.744000</td>\n",
       "      <td>2.284650</td>\n",
       "      <td>7.25</td>\n",
       "      <td>47.120000</td>\n",
       "      <td>0.916110</td>\n",
       "      <td>2.75</td>\n",
       "      <td>43.857747</td>\n",
       "      <td>1.415475</td>\n",
       "      <td>4.512292</td>\n",
       "      <td>44.412000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.710320</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>0.455506</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.165667</td>\n",
       "      <td>0.199453</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walking</th>\n",
       "      <td>18.816000</td>\n",
       "      <td>2.789475</td>\n",
       "      <td>11.00</td>\n",
       "      <td>46.261333</td>\n",
       "      <td>2.274938</td>\n",
       "      <td>7.75</td>\n",
       "      <td>34.433676</td>\n",
       "      <td>0.457919</td>\n",
       "      <td>1.683604</td>\n",
       "      <td>35.069333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.699922</td>\n",
       "      <td>0.057348</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>2.105833</td>\n",
       "      <td>0.082048</td>\n",
       "      <td>0.355</td>\n",
       "      <td>4.408167</td>\n",
       "      <td>0.108642</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              min_1_mean  min_1_std  min_1_<lambda_0>  max_1_mean  max_1_std  \\\n",
       "activityName                                                                   \n",
       "bending1       35.642857   2.030277              5.00   46.795714   1.275524   \n",
       "bending2       17.541667   9.995520             27.50   44.958333   6.581065   \n",
       "cycling        24.377333   3.358966             10.25   44.483333   0.476140   \n",
       "lying          33.216667  12.334934             48.00   42.733333   8.639697   \n",
       "sitting        35.544667   6.528011             19.00   46.356000   2.908998   \n",
       "standing       34.744000   2.284650              7.25   47.120000   0.916110   \n",
       "walking        18.816000   2.789475             11.00   46.261333   2.274938   \n",
       "\n",
       "              max_1_<lambda_0>  mean_1_mean  mean_1_std  mean_1_<lambda_0>  \\\n",
       "activityName                                                                 \n",
       "bending1                  3.00    42.667723    1.250419           3.344333   \n",
       "bending2                 18.00    29.415344    2.920310           8.023250   \n",
       "cycling                   1.50    36.747290    0.520192           1.808833   \n",
       "lying                    26.25    39.850217    7.142058          20.287792   \n",
       "sitting                  12.08    41.748634    3.424276          13.011688   \n",
       "standing                  2.75    43.857747    1.415475           4.512292   \n",
       "walking                   7.75    34.433676    0.457919           1.683604   \n",
       "\n",
       "              median_1_mean  ...  median_6_<lambda_0>  std_6_mean  std_6_std  \\\n",
       "activityName                 ...                                               \n",
       "bending1          42.904286  ...                0.070    0.531610   0.079900   \n",
       "bending2          28.993333  ...                0.440    0.905411   0.301775   \n",
       "cycling           36.221667  ...                0.890    1.749547   0.111433   \n",
       "lying             39.278000  ...                0.240    0.560337   0.119245   \n",
       "sitting           41.359000  ...                0.590    0.821134   0.150418   \n",
       "standing          44.412000  ...                0.590    0.710320   0.143333   \n",
       "walking           35.069333  ...                0.305    1.699922   0.057348   \n",
       "\n",
       "              std_6_<lambda_0>  1st_quart_6_mean  1st_quart_6_std  \\\n",
       "activityName                                                        \n",
       "bending1              0.233369          0.061429         0.162525   \n",
       "bending2              0.851877          0.468333         0.022286   \n",
       "cycling               0.395348          1.721167         0.230244   \n",
       "lying                 0.335581          0.340833         0.179044   \n",
       "sitting               0.542337          0.445333         0.023563   \n",
       "standing              0.455506          0.463333         0.023197   \n",
       "walking               0.174800          2.105833         0.082048   \n",
       "\n",
       "              1st_quart_6_<lambda_0>  3rd_quart_6_mean  3rd_quart_6_std  \\\n",
       "activityName                                                              \n",
       "bending1                       0.430          0.962857         0.279804   \n",
       "bending2                       0.070          1.168333         0.205175   \n",
       "cycling                        0.760          4.038333         0.281337   \n",
       "lying                          0.460          0.896667         0.080858   \n",
       "sitting                        0.070          1.145000         0.194008   \n",
       "standing                       0.070          1.165667         0.199453   \n",
       "walking                        0.355          4.408167         0.108642   \n",
       "\n",
       "              3rd_quart_6_<lambda_0>  \n",
       "activityName                          \n",
       "bending1                      0.8000  \n",
       "bending2                      0.4300  \n",
       "cycling                       0.9925  \n",
       "lying                         0.1700  \n",
       "sitting                       0.8700  \n",
       "standing                      0.7550  \n",
       "walking                       0.3250  \n",
       "\n",
       "[7 rows x 126 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing non numeric columns\n",
    "numberFeature = calculatedDataset.select_dtypes(include=[float, int])\n",
    "\n",
    "# grouping by activity label and calculating three key statistics for each feature:\n",
    "statistics = numberFeature.groupby(calculatedDataset[\"activityName\"]).agg([\"mean\", \"std\", lambda x: x.max() - x.min()])\n",
    "\n",
    "# renaming the columns\n",
    "statistics.columns = [\"_\".join(col).strip() for col in statistics.columns]\n",
    "\n",
    "# showing the statistics\n",
    "print(\"\\nFeature Statistics - Mean, Std, Range per Activity :\")\n",
    "statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the values observed from the Feature Summary Statistics the three most important time-domain features are:\n",
    "\n",
    "a) Mean: The mean value represents the overall average signal strength for each activity. From the table we can see that activities like bending1 (42.67) and walking (34.43) have different mean values, which helps differentiate between high and low-intensity activities.\n",
    "\n",
    "b) Standard Deviation: The standard deviation tells us how much the signal fluctuates. From the table we can see tha activities like bending2 (9.99) and lying (12.33) have high standard deviation, meaning these activities have high variations in movement while cycling (0.52) and walking (0.45) have low standard deviation, meaning the signal is more stable. This feature is useful because it helps differentiate dynamic and static activities.    \n",
    "\n",
    "c) Median: The median represents the middle value of the dataset, giving insight into the data's distribution.From the table we can see tha activities bending2 (28.99) has a lower median compared to its mean (29.41), which suggests the presence of some high-value spikes in the data.If the mean and median are close, the data is evenly spread. If they are far apart, the data is skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic model is more flexible than the linear model since it contains more terms, thus it will fit training data as good as, or even better than, the linear model. If the true relationship is linear, the cubic model can still provide slightly lower RSS by fitting noise. If it is nonlinear, the cubic model will provide lower RSS by fitting curves. But such flexibility can lead to overfitting, i.e., the training RSS for the cubic model is always equal or less but not necessarily superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model should have a lower test RSS since the true relationship is linear. The cubic model, with more parameters, may overfit the training data, capturing noise as opposed to the true pattern. Thus, it may fail to generalize well to new data, resulting in a higher test RSS compared to the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic model will have a lower or the same training RSS since its extra parameters enable it to fit data more accurately. The linear one may not be able to capture all the patterns if the real relationship is not precisely linear, thus it will have a higher RSS. The cubic model, while capable of fitting non-linear trends, can also overfit, so the lower RSS is less important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no clear information on the true relationship between X and Y, I can’t determine which model will perform better. The model that best matches the actual relationship will have a lower test RSS. If the relationship is closer to linear, the linear model will perform better. If it is closer to cubic, the cubic model will have a lower RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html                              https://www.geeksforgeeks.org/python-os-path-join-method/                                           https://www.geeksforgeeks.org/python-os-listdir-method                                              https://stackoverflow.com/questions/62867315/python-script-for-startswith-and-endswith              https://stackoverflow.com/questions/57023018/python-list-comprehension-execution-order/57023028\n",
    "https://docs.python.org/3/library/functions.html#enumerate\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html\n",
    "https://docs.python.org/2/library/stdtypes.html#str.join\n",
    "https://www.geeksforgeeks.org/numpy-zeros-python/\n",
    "https://numpy.org/doc/2.1/reference/generated/numpy.percentile.html\n",
    "https://stackoverflow.com/questions/13959510/python-list-initialization-using-multiple-range-statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
